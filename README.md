# -基于Spark平台利用信息熵实现中文分词-Demo

这是一个小的Demo尝试，实现中文分词

1.平台选择的是Spark,主要是借助此次练习熟悉Spark相关的知识；

2.中文分词，用的算法思路比较简单，从信息论的角度来解决中文分词的问题。

根据大数定律，我们知道，当样本越多时，其分布越接近真实的分布，样本发生的概率越接近于真实值。
